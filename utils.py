# utils.py
import google.generativeai as genai
from google.generativeai.types import GenerationConfig
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
import pickle
from pypdf import PdfReader
from docx import Document
from pathlib import Path
import uuid
from bs4 import BeautifulSoup
import markdown
from models import ChatMessage

# --- Gemini 2.5 Flash Setup ---
GEMINI_API_KEY = "AIzaSyAkB0ef-0Zs23Pa-N0ceZ3R2NBSFZHzDZI"
genai.configure(api_key=GEMINI_API_KEY)
MODEL_NAME = "gemini-2.5-flash"

# --- SYSTEM PROMPT ---
SYSTEM_PROMPT = """
You are a highly knowledgeable, reliable, and professional Legal Assistant specialized in **Nepalese Business Law**, especially for sectors like **Hospitality, Tourism, and SMEs**. Your task is to provide **clear, step-by-step, legally grounded guidance** to founders, entrepreneurs, and business professionals in Nepal. 

**Rules for answering:**
1. **Grounded in law only**
   - Use only verified Nepali laws and official sources (Acts, Regulations, Notifications).
   - Do not speculate or provide opinions.
   - Trusted sources: OCR, IRD, DoI, Department of Tourism.

2. **Structured responses**
   - Include sections: Direct Answer, Legal Basis, Practical Implication, Disclaimer.
   - Use bullet points, numbers, or step-by-step explanations.
   - Explain legal jargon where necessary.

3. **Context-sensitive**
   - Tailor answers based on business type (hotel, restaurant, trekking company, etc.).
   - Include procedural guidance where relevant.

4. **Language**
   - Respond in formal Nepali if the query is in Nepali.
   - Respond in English if the query is in English.

5. **Safety & Risk**
   - Highlight ambiguity or uncertainty.
   - Advise consulting a licensed lawyer if required.
   - Prefer silence over confident wrong answers.

6. **RAG integration**
   - Use retrieved document excerpts to construct responses.
   - Indicate sources where relevant.

7. **Tone**
   - Professional, concise, precise.
   - Use **one subtle emoji ðŸ™‚** only if it adds clarity or warmth.

8. **Introduction**
   - Respond briefly if asked "Who are you?".
   - Do not answer legal queries in introductions.

**Scope**
- Company registration & sector-specific licenses
- Tax compliance (PAN/VAT) & filing
- Labor law, contracts, benefits
- Intellectual Property (trademarks, patents, copyrights)
- Tourism & hospitality regulations
- Other Nepali business laws (Food Act, Consumer Protection Act, Tourism Act, etc.)

**Disclaimer**
*This response is generated by LegalEase Nepal, a domain-specific AI assistant. The information is extracted from verified Nepali legal documents and official sources. While every effort is made to ensure accuracy, the system is under active development and may not capture all nuances of the law. The response is for informational purposes only and does not replace professional legal advice.*
"""


# --- Paths ---
INDEX_PATH = "faiss_index"
EMBEDDINGS_PATH = "embeddings.pkl"

vectorstore = None
retriever = None

# --- Embeddings ---
def get_embeddings():
    return HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# --- Load or create vector store ---
try:
    print("Loading embeddings...")
    with open(EMBEDDINGS_PATH, "rb") as f:
        embeddings = pickle.load(f)
    if not isinstance(embeddings, HuggingFaceEmbeddings):
        raise ValueError("Incompatible embeddings type")
    print("Loading FAISS index...")
    vectorstore = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})  # Increased k for full answers
    print("Vector store loaded successfully")
except Exception as e:
    print(f"Error loading vector store: {e}. Will create fresh embeddings on first upload.")
    embeddings = get_embeddings()
    with open(EMBEDDINGS_PATH, "wb") as f:
        pickle.dump(embeddings, f)
    vectorstore = None
    retriever = None

# --- Extract text from files ---
def extract_text(file, file_path: str) -> str:
    ext = Path(file.filename).suffix.lower()
    text = ""
    if ext == ".pdf":
        with open(file_path, "rb") as f:
            pdf = PdfReader(f)
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + " "
    elif ext in [".docx", ".doc"]:
        doc = Document(file_path)
        text = " ".join(p.text for p in doc.paragraphs)
    elif ext == ".txt":
        with open(file_path, "r", encoding="utf-8") as f:
            text = f.read()
    print(f"Extracted text length from {file.filename}: {len(text)}")
    return text.strip()

# --- Update vector store with new docs ---
def update_vector_store(file_id: str, text: str, filename: str):
    global vectorstore, retriever
    if not text.strip():
        return
    embeddings = get_embeddings()
    if vectorstore is None:
        vectorstore = FAISS.from_texts(
            [text],
            embeddings,
            metadatas=[{"source": filename, "file_id": file_id}],
            ids=[file_id]
        )
    else:
        vectorstore.add_texts(
            [text],
            metadatas=[{"source": filename, "file_id": file_id}],
            ids=[file_id]
        )
    vectorstore.save_local(INDEX_PATH)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})  # Ensure multiple chunks retrieved
    print("Vector store updated successfully")

# --- Get legal response ---
def get_legal_response(query: str, chat_history=None) -> dict:
    sources = []
    context = ""
    found_in_pdf = False
    
    if retriever:
        try:
            docs = retriever.get_relevant_documents(query)
            for doc in docs:
                source = doc.metadata.get("source", "Unknown")
                context += f"\n\nDocument: {source}\n{doc.page_content}"
                if source.lower().endswith('.pdf'):
                    found_in_pdf = True
                    sources.append({
                        "content": doc.page_content[:200] + "...",
                        "source": source
                    })
            print(f"Retrieved {len(docs)} relevant documents for RAG")
        except Exception as e:
            print(f"RAG Error: {e}")

    prompt_text = f"""
{SYSTEM_PROMPT}

RELEVANT DOCUMENT EXCERPTS:
{context}

USER QUERY: {query}

Provide a clear, complete, and professional response in markdown format using the document excerpts.
"""

    try:
        model = genai.GenerativeModel(
            MODEL_NAME,
            generation_config=GenerationConfig(
                temperature=0.2,
                top_p=0.8,
                top_k=40,
                max_output_tokens=4096,  # Increased for long legal answers
            )
        )
        response = model.generate_content(prompt_text)
        raw_answer = response.text if hasattr(response, "text") else str(response)
    except Exception as e:
        print(f"Gemini Error: {str(e)}")
        raw_answer = "Sorry, the AI service is temporarily unavailable."

    # Convert to HTML for frontend
    raw_answer = raw_answer.replace("```html", "").replace("```", "")
    html_answer = markdown.markdown(raw_answer)
    soup = BeautifulSoup(html_answer, 'html.parser')

    # Add CSS classes
    for tag in soup.find_all(['h1','h2','h3','h4','h5','h6']):
        tag['class'] = tag.get('class', []) + ['legal-heading']
    for tag in soup.find_all('p'):
        tag['class'] = tag.get('class', []) + ['legal-paragraph']
    for tag in soup.find_all(['ul','ol']):
        tag['class'] = tag.get('class', []) + ['legal-list']
    for tag in soup.find_all('li'):
        tag['class'] = tag.get('class', []) + ['legal-list-item']
    for tag in soup.find_all(['strong','b']):
        tag['class'] = tag.get('class', []) + ['legal-bold']
    for tag in soup.find_all(['em','i']):
        tag['class'] = tag.get('class', []) + ['legal-italic']

    formatted_answer = str(soup)
    show_sources = found_in_pdf and len(query.split()) > 2

    return {
        "response": formatted_answer,
        "sources": sources if show_sources else []
    }
